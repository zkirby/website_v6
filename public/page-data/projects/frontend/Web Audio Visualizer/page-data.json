{"componentChunkName":"component---src-components-markdown-markdown-jsx","path":"/projects/frontend/Web Audio Visualizer","result":{"data":{"markdownRemark":{"html":"<h1>web.play</h1>\n<p><strong>visit: <a href=\"https://zkirby.com/web_audio_visualizer/\">audio.play</a></strong></p>\n<p><img src=\"IMG_PATH/audio-home.png\" alt=\"Home Screen\"></p>\n<p>Web.play was inspired by FLStudio. At the time I was exploring the software and creating music through it as an admittedly short lived hobby. After coming to the stark realization that I was never going to be a great beat maker I put the FruityLoops aside - but I wasn't done exploring music. I started digging around the MDN docs looking for some sort of music related-project I could make with JS. I stumbled onto the WebAudio API and was immediately intrigued both with it's complexity and with the graph-like representation the docs detailed it in.</p>\n<p>After a week or so digging around the documentation I was having a hard time visualizing the interactions between the various nodes and their roles. I liked the idea of building something that would bring tangibility to the audio nodes in a flowchart-esque representation and thus Web.play was born.</p>\n<p><img src=\"IMG_PATH/audio-play.png\" alt=\"Home Screen\"></p>\n<p>In essence, web.play is a graph-driven software for visualizing the WebAudio API. You interact with nodes as if they were legos - connecting them to each other such that some set of constraints is met that allows sound to travel from one end of the tree to the other.</p>\n<p>My ambitions were originally to support every AudioNode but alas I decided to move on after I had reached a point where I was satisfied with what I had made.</p>","frontmatter":{"slug":"/projects/frontend/Web Audio Visualizer","date":"2021-04-11","section":"projects","subsection":"Frontend"}}},"pageContext":{"slug":"/projects/frontend/Web Audio Visualizer","section":"projects","subsection":"Frontend","doNotList":null}},"staticQueryHashes":[]}